本项目采用`langchain-dev-utils`中的工具函数`load_chat_model`来加载不同的大模型。

该函数通过注册`register_model_provider`注册不同的模型提供商，然后利用`load_chat_model`函数加载不同的模型。

具体可以参考该库的 github 仓库 [https://github.com/TBice123123/langchain-dev-utils]

本项目替换模型的方式：
修改 src/agent/utils/context.py 中的 Context 类中的字段值即可。

目前支持的模型有：

- Qwen 模型（dashscope)
- GLM 模型（zai)
- 各大厂商开源部署的模型（siliconflow)
- Kimi 模型（moonshot)
- DeepSeek 模型（deepseek)

目前对于智能体所使用的模型如下：
主智能体：kimi-k2-0905-preview
子智能体：deepseek-v3.2

此外还有 qwen-flash 用于做任务总结摘要的生成（这里可以换成 glm4.5-air 或者 qwen3-30b-a3b-2507-instruct 等模型）
你需要有这些模型的 API Key，当然如果你也可以换成你自己的模型。或者采用硅基流动中的对应的开源模型。（qwen-flash 是闭源的，可以使用 qwen3-30b-a3b-2507-instruct 代替)
